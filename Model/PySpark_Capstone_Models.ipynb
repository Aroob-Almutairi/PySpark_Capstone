{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dd14ba",
   "metadata": {},
   "source": [
    "# BigData Capstone\n",
    "\n",
    "## Group: U_Data\n",
    "\n",
    "    Members:\n",
    "    \n",
    "    Aroob Almutairi \n",
    "    \n",
    "    Abdulrahman Alosaimi\n",
    "    \n",
    "    Duaa Al saad \n",
    "    \n",
    "    Fatimah Alateeq\n",
    "    \n",
    "    Ghaliah mohammedhussein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460fbba",
   "metadata": {},
   "source": [
    "## Project describtion\n",
    "\n",
    "We build 4 models of each classification and regression. We used salary as our target in classification, and capital gain in regression.\n",
    "\n",
    "## Pre-Processing\n",
    "\n",
    "1. Replaced the '?' in all the columns with Not-specified\n",
    "2. Made the values for education consistent\n",
    "3. Changed the values for salary to be 0 if <=50k, and 1 if >50k\n",
    "4. Sumed the values for the fnlwgt column, and get the percentage of fnlwgt\n",
    "5. Found the difference between capital gain and loss\n",
    "6. Found the workholic people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65373b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b941f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "#lets import our usual suspects\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#pyspark related imports\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor, GBTRegressor, LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35e07fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:14:03 WARN Utils: Your hostname, ghalyts-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.13 instead (on interface en0)\n",
      "22/12/26 14:14:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:14:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.memory\", \"8g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26907d",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e35c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "dfs = spark.read.csv('Cleaned_Data.csv',inferSchema=True,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7728c8ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                        (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 15\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: integer (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital_gain: integer (nullable = true)\n",
      " |-- capital_loss: integer (nullable = true)\n",
      " |-- hours_per_week: integer (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# The data Shape\n",
    "print(dfs.count(), len(dfs.columns))\n",
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb423e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|age|       workclass|fnlwgt|education|education_num|    marital_status|       occupation| relationship| race|gender|capital_gain|capital_loss|hours_per_week|native_country|salary|\n",
      "+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "| 39|       State-gov| 77516|Bachelors|           13|     Never-married|     Adm-clerical|Not-in-family|White|  Male|        2174|           0|            40| United-States| <=50K|\n",
      "| 50|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|           0|           0|            13| United-States| <=50K|\n",
      "| 38|         Private|215646|  HS-grad|            9|          Divorced|Handlers-cleaners|Not-in-family|White|  Male|           0|           0|            40| United-States| <=50K|\n",
      "| 53|         Private|234721|     11th|            7|Married-civ-spouse|Handlers-cleaners|      Husband|Black|  Male|           0|           0|            40| United-States| <=50K|\n",
      "| 28|         Private|338409|Bachelors|           13|Married-civ-spouse|   Prof-specialty|         Wife|Black|Female|           0|           0|            40|          Cuba| <=50K|\n",
      "+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69003e06",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ccc0ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#This step will label encode all the categorical columns and store them in different columns with the same name + '_idx', \n",
    "#so category will become category_idx \n",
    "cat_cols = ['workclass', 'education', 'marital_status','occupation','relationship','race','gender','native_country']\n",
    "\n",
    "for c in cat_cols: \n",
    "    indexer = StringIndexer(inputCol=c, outputCol=c+'_idx') \n",
    "    dfs = indexer.fit(dfs).transform(dfs) \n",
    "    \n",
    "final_df = dfs.drop(*cat_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec34f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------+------------+------------+--------------+------+-----------------+---------------------------+------+----------+-------------+-------------+------------------+--------------+----------------+--------+----------+------------------+\n",
      "|age|fnlwgt|education_num|capital_gain|capital_loss|hours_per_week|salary|fnlwgt_percentage|diffrence_capital_gain_loos|profit|workaholic|workclass_idx|education_idx|marital_status_idx|occupation_idx|relationship_idx|race_idx|gender_idx|native_country_idx|\n",
      "+---+------+-------------+------------+------------+--------------+------+-----------------+---------------------------+------+----------+-------------+-------------+------------------+--------------+----------------+--------+----------+------------------+\n",
      "| 39| 77516|           13|        2174|           0|            40|     0|              0.0|                       2174|     1|         0|          4.0|          2.0|               1.0|           5.0|             1.0|     0.0|       0.0|               3.0|\n",
      "| 50| 83311|           13|           0|           0|            13|     0|              0.0|                          0|     0|         0|          1.0|          2.0|               0.0|           1.0|             0.0|     0.0|       0.0|               3.0|\n",
      "| 38|215646|            9|           0|           0|            40|     0|              0.0|                          0|     0|         0|          0.0|          0.0|               2.0|           8.0|             1.0|     0.0|       0.0|               3.0|\n",
      "| 53|234721|            7|           0|           0|            40|     0|              0.0|                          0|     0|         0|          0.0|          3.0|               0.0|           8.0|             0.0|     1.0|       0.0|               3.0|\n",
      "| 28|338409|           13|           0|           0|            40|     0|              0.0|                          0|     0|         0|          0.0|          2.0|               0.0|           2.0|             4.0|     1.0|       1.0|               2.0|\n",
      "| 37|284582|           14|           0|           0|            40|     0|              0.0|                          0|     0|         0|          0.0|          5.0|               0.0|           1.0|             4.0|     0.0|       1.0|               3.0|\n",
      "| 49|160187|            5|           0|           0|            16|     0|              0.0|                          0|     0|         0|          0.0|         12.0|               6.0|           3.0|             1.0|     1.0|       1.0|               2.0|\n",
      "| 52|209642|            9|           0|           0|            45|     1|              0.0|                          0|     0|         0|          1.0|          0.0|               0.0|           1.0|             0.0|     0.0|       0.0|               3.0|\n",
      "| 31| 45781|           14|       14084|           0|            50|     1|              0.0|                      14084|     1|         0|          0.0|          5.0|               1.0|           2.0|             1.0|     0.0|       1.0|               3.0|\n",
      "| 42|159449|           13|        5178|           0|            40|     1|              0.0|                       5178|     1|         0|          0.0|          2.0|               0.0|           1.0|             0.0|     0.0|       0.0|               3.0|\n",
      "| 37|280464|           10|           0|           0|            80|     1|              0.0|                          0|     0|         1|          0.0|          1.0|               0.0|           1.0|             0.0|     1.0|       0.0|               3.0|\n",
      "| 30|141297|           13|           0|           0|            40|     1|              0.0|                          0|     0|         0|          4.0|          2.0|               0.0|           2.0|             0.0|     3.0|       0.0|               0.0|\n",
      "| 23|122272|           13|           0|           0|            30|     0|              0.0|                          0|     0|         0|          0.0|          2.0|               1.0|           5.0|             2.0|     0.0|       1.0|               3.0|\n",
      "| 32|205019|           12|           0|           0|            50|     0|              0.0|                          0|     0|         0|          0.0|          7.0|               1.0|           4.0|             1.0|     1.0|       0.0|               3.0|\n",
      "| 40|121772|           11|           0|           0|            40|     1|              0.0|                          0|     0|         0|          0.0|          4.0|               0.0|           0.0|             0.0|     3.0|       0.0|               7.0|\n",
      "| 34|245487|            4|           0|           0|            45|     0|              0.0|                          0|     0|         0|          0.0|          8.0|               0.0|           9.0|             0.0|     2.0|       0.0|               3.0|\n",
      "| 25|176756|            9|           0|           0|            35|     0|              0.0|                          0|     0|         0|          1.0|          0.0|               1.0|          11.0|             2.0|     0.0|       0.0|               3.0|\n",
      "| 32|186824|            9|           0|           0|            40|     0|              0.0|                          0|     0|         0|          0.0|          0.0|               1.0|           6.0|             3.0|     0.0|       0.0|               3.0|\n",
      "| 38| 28887|            7|           0|           0|            50|     0|              0.0|                          0|     0|         0|          0.0|          3.0|               0.0|           4.0|             0.0|     0.0|       0.0|               3.0|\n",
      "| 43|292175|           14|           0|           0|            45|     1|              0.0|                          0|     0|         0|          1.0|          5.0|               2.0|           1.0|             3.0|     0.0|       1.0|               3.0|\n",
      "+---+------+-------------+------------+------------+--------------+------+-----------------+---------------------------+------+----------+-------------+-------------+------------------+--------------+----------------+--------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1ac5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs=dfs.where(dfs.native_country!='South')\n",
    "final_df = final_df.withColumn(\"fnlwgt_percentage\", dfs[\"fnlwgt_percentage\"].cast('int'))\n",
    "final_df = final_df.withColumn(\"workclass_idx\", dfs[\"workclass_idx\"].cast('int'))\n",
    "final_df = final_df.withColumn(\"education_idx\", dfs[\"education_idx\"].cast('int'))\n",
    "final_df = final_df.withColumn(\"marital_status_idx\", dfs[\"marital_status_idx\"].cast('int'))\n",
    "final_df = final_df.withColumn(\"occupation_idx\", dfs[\"occupation_idx\"].cast('int'))\n",
    "final_df = final_df.withColumn(\"relationship_idx\", dfs[\"relationship_idx\"].cast('int'))\n",
    "\n",
    "final_df = final_df.withColumn(\"race_idx\", dfs[\"race_idx\"].cast('int'))\n",
    "final_df = final_df.withColumn(\"gender_idx\", dfs[\"gender_idx\"].cast('int'))\n",
    "final_df = final_df.withColumn(\"native_country_idx\", dfs[\"native_country_idx\"].cast('int'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ff44b",
   "metadata": {},
   "source": [
    "## Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39199c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = final_df.columns # Extract the column names from the dataframe\n",
    "cols.remove('salary') #remove salary because it is our target in clasification \n",
    "\n",
    "#vector assembler will take all the columns and convert them into one column called features\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "final_df = assembler.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b273328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:17:17 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+---+------+-------------+------------+------------+--------------+------+-----------------+---------------------------+------+----------+-------------+-------------+------------------+--------------+----------------+--------+----------+------------------+--------------------------------------------------------------------------------------+\n",
      "|age|fnlwgt|education_num|capital_gain|capital_loss|hours_per_week|salary|fnlwgt_percentage|diffrence_capital_gain_loos|profit|workaholic|workclass_idx|education_idx|marital_status_idx|occupation_idx|relationship_idx|race_idx|gender_idx|native_country_idx|features                                                                              |\n",
      "+---+------+-------------+------------+------------+--------------+------+-----------------+---------------------------+------+----------+-------------+-------------+------------------+--------------+----------------+--------+----------+------------------+--------------------------------------------------------------------------------------+\n",
      "|39 |77516 |13           |2174        |0           |40            |0     |0                |2174                       |1     |0         |4            |2            |1                 |5             |1               |0       |0         |3                 |[39.0,77516.0,13.0,2174.0,0.0,40.0,0.0,2174.0,1.0,0.0,4.0,2.0,1.0,5.0,1.0,0.0,0.0,3.0]|\n",
      "|50 |83311 |13           |0           |0           |13            |0     |0                |0                          |0     |0         |1            |2            |0                 |1             |0               |0       |0         |3                 |(18,[0,1,2,5,10,11,13,17],[50.0,83311.0,13.0,13.0,1.0,2.0,1.0,3.0])                   |\n",
      "|38 |215646|9            |0           |0           |40            |0     |0                |0                          |0     |0         |0            |0            |2                 |8             |1               |0       |0         |3                 |(18,[0,1,2,5,12,13,14,17],[38.0,215646.0,9.0,40.0,2.0,8.0,1.0,3.0])                   |\n",
      "|53 |234721|7            |0           |0           |40            |0     |0                |0                          |0     |0         |0            |3            |0                 |8             |0               |1       |0         |3                 |(18,[0,1,2,5,11,13,15,17],[53.0,234721.0,7.0,40.0,3.0,8.0,1.0,3.0])                   |\n",
      "|28 |338409|13           |0           |0           |40            |0     |0                |0                          |0     |0         |0            |2            |0                 |2             |4               |1       |1         |2                 |(18,[0,1,2,5,11,13,14,15,16,17],[28.0,338409.0,13.0,40.0,2.0,2.0,4.0,1.0,1.0,2.0])    |\n",
      "+---+------+-------------+------------+------------+--------------+------+-----------------+---------------------------+------+----------+-------------+-------------+------------------+--------------+----------------+--------+----------+------------------+--------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2be40c",
   "metadata": {},
   "source": [
    "#### Lets Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b295cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now create a new dataframe only consisting of the features column and the label column\n",
    "df_data = final_df.select(col('features'), col('salary').alias('label'))\n",
    "\n",
    "#simple data splitting\n",
    "df_train, df_test = df_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a5f72",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "Our data is now ready for some model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd92aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "model_dt = dt.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7c4a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
    "model_rf = rf.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0f7173e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 166:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:19:04 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/12/26 14:19:04 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, labelCol=\"label\", featuresCol=\"features\")\n",
    "model_lr = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a0afc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Gradient Boost\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "model_gbt = gbt.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b2cf9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make the predictions on the testing set\n",
    "pred_dt = model_dt.transform(df_test)\n",
    "pred_rf = model_rf.transform(df_test)\n",
    "pred_lr = model_lr.transform(df_test)\n",
    "pred_gbt = model_gbt.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045117e",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c2a8c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_A = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# F1 Metric\n",
    "evaluator_F = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Weighted Precision\n",
    "evaluator_P = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "\n",
    "# Weighted Recall\n",
    "evaluator_R = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# Our models\n",
    "models = [pred_dt, pred_rf, pred_lr, pred_gbt]\n",
    "\n",
    "# Empty lists that will store the scores for each metric for each model.\n",
    "accuracy = []\n",
    "F1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "# loop to populate the empty lists with scores of models for each metric.\n",
    "for model in models:\n",
    "    accuracy.append(evaluator_A.evaluate(model))\n",
    "    F1.append(evaluator_F.evaluate(model))\n",
    "    precision.append(evaluator_P.evaluate(model))\n",
    "    recall.append(evaluator_R.evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f55e042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will convert all lists created above into a dataframe for easy viewing.\n",
    "df_ev = pd.DataFrame(list(zip(accuracy, F1, precision, recall)), \n",
    "                     columns = ['Accuracy', 'F1-Score', 'Weighted Precision', 'Weighted Recall'],\n",
    "                     index = ['Decision Tree', 'Random Forest', 'Logistic Regression', 'Gradient Boost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05255017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.509883</td>\n",
       "      <td>0.443157</td>\n",
       "      <td>0.510274</td>\n",
       "      <td>0.509883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.495179</td>\n",
       "      <td>0.507634</td>\n",
       "      <td>0.508909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.506525</td>\n",
       "      <td>0.340609</td>\n",
       "      <td>0.256568</td>\n",
       "      <td>0.506525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.511259</td>\n",
       "      <td>0.505039</td>\n",
       "      <td>0.510369</td>\n",
       "      <td>0.511259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  F1-Score  Weighted Precision  Weighted Recall\n",
       "Decision Tree        0.509883  0.443157            0.510274         0.509883\n",
       "Random Forest        0.508909  0.495179            0.507634         0.508909\n",
       "Logistic Regression  0.506525  0.340609            0.256568         0.506525\n",
       "Gradient Boost       0.511259  0.505039            0.510369         0.511259"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816b2732",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning - Best Two Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2436b",
   "metadata": {},
   "source": [
    "Choosing Decision Tree and Gradient Boosted Trees instead of Linear Regression because of the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43bb796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76411223",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd787dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize our grid \n",
    "grid2 = ParamGridBuilder().addGrid(dt.maxDepth, [5, 10, 15, 20 , 25]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d88ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CrossValidator\n",
    "cv_reg2 = CrossValidator(estimator=dt, estimatorParamMaps=grid2, evaluator=evaluator_A, parallelism=2, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74f22a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:29:53 WARN DAGScheduler: Broadcasting large task binary with size 1054.3 KiB\n",
      "22/12/26 14:29:54 WARN DAGScheduler: Broadcasting large task binary with size 1054.3 KiB\n",
      "22/12/26 14:29:54 WARN DAGScheduler: Broadcasting large task binary with size 1382.6 KiB\n",
      "22/12/26 14:29:54 WARN DAGScheduler: Broadcasting large task binary with size 1382.6 KiB\n",
      "22/12/26 14:29:55 WARN DAGScheduler: Broadcasting large task binary with size 1806.1 KiB\n",
      "22/12/26 14:29:55 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:29:56 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "22/12/26 14:29:57 WARN DAGScheduler: Broadcasting large task binary with size 1113.6 KiB\n",
      "22/12/26 14:29:57 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "22/12/26 14:29:58 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:29:59 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "22/12/26 14:30:05 WARN DAGScheduler: Broadcasting large task binary with size 1054.3 KiB\n",
      "22/12/26 14:30:06 WARN DAGScheduler: Broadcasting large task binary with size 1382.6 KiB\n",
      "22/12/26 14:30:07 WARN DAGScheduler: Broadcasting large task binary with size 1806.1 KiB\n",
      "22/12/26 14:30:07 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:30:08 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "22/12/26 14:30:09 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "22/12/26 14:30:11 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:12 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:14 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:16 WARN DAGScheduler: Broadcasting large task binary with size 9.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:18 WARN DAGScheduler: Broadcasting large task binary with size 11.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:20 WARN DAGScheduler: Broadcasting large task binary with size 13.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:22 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:47 WARN DAGScheduler: Broadcasting large task binary with size 1054.8 KiB\n",
      "22/12/26 14:30:47 WARN DAGScheduler: Broadcasting large task binary with size 1054.8 KiB\n",
      "22/12/26 14:30:48 WARN DAGScheduler: Broadcasting large task binary with size 1399.3 KiB\n",
      "22/12/26 14:30:48 WARN DAGScheduler: Broadcasting large task binary with size 1399.3 KiB\n",
      "22/12/26 14:30:48 WARN DAGScheduler: Broadcasting large task binary with size 1852.4 KiB\n",
      "22/12/26 14:30:49 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "22/12/26 14:30:49 WARN DAGScheduler: Broadcasting large task binary with size 1134.9 KiB\n",
      "22/12/26 14:30:49 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "22/12/26 14:30:50 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "22/12/26 14:30:51 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:53 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "22/12/26 14:30:53 WARN DAGScheduler: Broadcasting large task binary with size 1054.8 KiB\n",
      "22/12/26 14:30:54 WARN DAGScheduler: Broadcasting large task binary with size 1399.3 KiB\n",
      "22/12/26 14:30:54 WARN DAGScheduler: Broadcasting large task binary with size 1852.4 KiB\n",
      "22/12/26 14:30:55 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "22/12/26 14:30:55 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "22/12/26 14:30:56 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "22/12/26 14:30:57 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "22/12/26 14:30:58 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:30:59 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "22/12/26 14:31:00 WARN DAGScheduler: Broadcasting large task binary with size 9.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:01 WARN DAGScheduler: Broadcasting large task binary with size 10.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:03 WARN DAGScheduler: Broadcasting large task binary with size 12.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:05 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:30 WARN DAGScheduler: Broadcasting large task binary with size 1085.6 KiB\n",
      "22/12/26 14:31:30 WARN DAGScheduler: Broadcasting large task binary with size 1085.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 810:>                                                      (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:31 WARN DAGScheduler: Broadcasting large task binary with size 1447.1 KiB\n",
      "22/12/26 14:31:31 WARN DAGScheduler: Broadcasting large task binary with size 1447.1 KiB\n",
      "22/12/26 14:31:31 WARN DAGScheduler: Broadcasting large task binary with size 1924.5 KiB\n",
      "22/12/26 14:31:32 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "22/12/26 14:31:33 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "22/12/26 14:31:33 WARN DAGScheduler: Broadcasting large task binary with size 1169.8 KiB\n",
      "22/12/26 14:31:33 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "22/12/26 14:31:34 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:36 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "22/12/26 14:31:37 WARN DAGScheduler: Broadcasting large task binary with size 1085.6 KiB\n",
      "22/12/26 14:31:38 WARN DAGScheduler: Broadcasting large task binary with size 1447.1 KiB\n",
      "22/12/26 14:31:38 WARN DAGScheduler: Broadcasting large task binary with size 1924.5 KiB\n",
      "22/12/26 14:31:38 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "22/12/26 14:31:39 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "22/12/26 14:31:39 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "22/12/26 14:31:40 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "22/12/26 14:31:41 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:43 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:44 WARN DAGScheduler: Broadcasting large task binary with size 10.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:46 WARN DAGScheduler: Broadcasting large task binary with size 13.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:48 WARN DAGScheduler: Broadcasting large task binary with size 15.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:31:50 WARN DAGScheduler: Broadcasting large task binary with size 10.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:32:32 WARN DAGScheduler: Broadcasting large task binary with size 1162.0 KiB\n",
      "22/12/26 14:32:32 WARN DAGScheduler: Broadcasting large task binary with size 1162.0 KiB\n",
      "22/12/26 14:32:33 WARN DAGScheduler: Broadcasting large task binary with size 1599.9 KiB\n",
      "22/12/26 14:32:33 WARN DAGScheduler: Broadcasting large task binary with size 1599.9 KiB\n",
      "22/12/26 14:32:33 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:32:34 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "22/12/26 14:32:34 WARN DAGScheduler: Broadcasting large task binary with size 1303.9 KiB\n",
      "22/12/26 14:32:35 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "22/12/26 14:32:35 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "22/12/26 14:32:37 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n",
      "22/12/26 14:32:38 WARN DAGScheduler: Broadcasting large task binary with size 4.9 MiB\n",
      "22/12/26 14:32:39 WARN DAGScheduler: Broadcasting large task binary with size 1162.0 KiB\n",
      "22/12/26 14:32:39 WARN DAGScheduler: Broadcasting large task binary with size 1599.9 KiB\n",
      "22/12/26 14:32:39 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:32:40 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "22/12/26 14:32:41 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "22/12/26 14:32:41 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "22/12/26 14:32:42 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:32:44 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:32:46 WARN DAGScheduler: Broadcasting large task binary with size 10.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:32:48 WARN DAGScheduler: Broadcasting large task binary with size 12.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:32:50 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:32:52 WARN DAGScheduler: Broadcasting large task binary with size 17.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:32:54 WARN DAGScheduler: Broadcasting large task binary with size 11.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:33:17 WARN DAGScheduler: Broadcasting large task binary with size 1059.3 KiB\n",
      "22/12/26 14:33:17 WARN DAGScheduler: Broadcasting large task binary with size 1059.3 KiB\n",
      "22/12/26 14:33:18 WARN DAGScheduler: Broadcasting large task binary with size 1405.1 KiB\n",
      "22/12/26 14:33:18 WARN DAGScheduler: Broadcasting large task binary with size 1405.1 KiB\n",
      "22/12/26 14:33:18 WARN DAGScheduler: Broadcasting large task binary with size 1876.7 KiB\n",
      "22/12/26 14:33:18 WARN DAGScheduler: Broadcasting large task binary with size 1141.6 KiB\n",
      "22/12/26 14:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "22/12/26 14:33:19 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "22/12/26 14:33:20 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "22/12/26 14:33:21 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "22/12/26 14:33:23 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "22/12/26 14:33:23 WARN DAGScheduler: Broadcasting large task binary with size 1059.3 KiB\n",
      "22/12/26 14:33:23 WARN DAGScheduler: Broadcasting large task binary with size 1405.1 KiB\n",
      "22/12/26 14:33:24 WARN DAGScheduler: Broadcasting large task binary with size 1876.7 KiB\n",
      "22/12/26 14:33:24 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "22/12/26 14:33:25 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "22/12/26 14:33:25 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "22/12/26 14:33:26 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "22/12/26 14:33:27 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "22/12/26 14:33:28 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:33:30 WARN DAGScheduler: Broadcasting large task binary with size 10.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:33:31 WARN DAGScheduler: Broadcasting large task binary with size 13.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:33:34 WARN DAGScheduler: Broadcasting large task binary with size 15.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:33:36 WARN DAGScheduler: Broadcasting large task binary with size 10.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:34:19 WARN DAGScheduler: Broadcasting large task binary with size 1107.8 KiB\n",
      "22/12/26 14:34:19 WARN DAGScheduler: Broadcasting large task binary with size 1507.8 KiB\n",
      "22/12/26 14:34:19 WARN DAGScheduler: Broadcasting large task binary with size 2044.0 KiB\n",
      "22/12/26 14:34:20 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "22/12/26 14:34:20 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "22/12/26 14:34:21 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n",
      "22/12/26 14:34:22 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "cv_reg2Model = cv_reg2.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fcc74415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:34:24 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5104290120188941"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_A.evaluate(cv_reg2Model.transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b99d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5111982426011041,\n",
       " 0.5110948248851509,\n",
       " 0.511050237858857,\n",
       " 0.5123282059493637,\n",
       " 0.5113149416538245]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average metrics on 4 different models \n",
    "cv_reg2Model.avgMetrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e16557",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cede8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize our grid \n",
    "grid = ParamGridBuilder().addGrid(gbt.maxIter, [40, 30, 15, 20 , 25]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc8006fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CrossValidator\n",
    "cv_reg = CrossValidator(estimator=gbt, estimatorParamMaps=grid, evaluator=evaluator_A, parallelism=2, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0cd3a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1328:>               (0 + 1) / 1][Stage 1329:>               (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:35:36 WARN BlockManager: Block rdd_3225_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "cv_regModel = cv_reg.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04d66a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.510227501716253"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_A.evaluate(cv_regModel.transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d595a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5112795685286986,\n",
       " 0.5109166269336128,\n",
       " 0.5111943914651279,\n",
       " 0.5110155481331214,\n",
       " 0.5112882614779906]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average metrics on 4 different models \n",
    "cv_regModel.avgMetrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e685bae",
   "metadata": {},
   "source": [
    "### Pipeline - Best Two Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "209304e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d38f1",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50ebc387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline containing PCA and Decision Tree\n",
    "pca = PCA(k=5, inputCol='features', outputCol='pcaFeature')\n",
    "dt_1 = DecisionTreeClassifier(maxDepth=10)\n",
    "pipeline = Pipeline (stages=[pca, dt_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92c57260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:43:40 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/12/26 14:43:40 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "pipeline_model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c8aaba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5127378419271216"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_R.evaluate(pipeline_model.transform(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67393b",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97085c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline containing PCA and Gradient Boosted Trees \n",
    "pca1 = PCA(k=5, inputCol='features', outputCol='pcaFeature')\n",
    "GBTR_1 = GBTClassifier(maxIter = 20)\n",
    "pipeline2 = Pipeline (stages=[pca1, GBTR_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "017b8c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "pipeline_model2 = pipeline2.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14178bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5105383057423605"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_R.evaluate(pipeline_model2.transform(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36806c7",
   "metadata": {},
   "source": [
    "## Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12971c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = dfs.drop(*cat_cols) \n",
    "# dfs=dfs.where(dfs.native_country!='South')\n",
    "final_df2 = final_df2.withColumn(\"fnlwgt_percentage\", dfs[\"fnlwgt_percentage\"].cast('int'))\n",
    "final_df2 = final_df2.withColumn(\"workclass_idx\", dfs[\"workclass_idx\"].cast('int'))\n",
    "final_df2 = final_df2.withColumn(\"education_idx\", dfs[\"education_idx\"].cast('int'))\n",
    "final_df2 = final_df2.withColumn(\"marital_status_idx\", dfs[\"marital_status_idx\"].cast('int'))\n",
    "final_df2 = final_df2.withColumn(\"occupation_idx\", dfs[\"occupation_idx\"].cast('int'))\n",
    "final_df2 = final_df2.withColumn(\"relationship_idx\", dfs[\"relationship_idx\"].cast('int'))\n",
    "\n",
    "final_df2 = final_df2.withColumn(\"race_idx\", dfs[\"race_idx\"].cast('int'))\n",
    "final_df2 = final_df2.withColumn(\"gender_idx\", dfs[\"gender_idx\"].cast('int'))\n",
    "final_df2 = final_df2.withColumn(\"native_country_idx\", dfs[\"native_country_idx\"].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00591132",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = final_df2.columns \n",
    "cols.remove('capital_gain') #remove capital_gain because it is our target in regression \n",
    "\n",
    "#vector assembler will take all the columns and convert them into one column called features\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "assembler_df = assembler.transform(final_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f05d6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now create a new dataframe only consisting of the features column and the label column \n",
    "df_reg = assembler_df.select(col('features'), col('capital_gain').alias('label'))\n",
    "\n",
    "#simple data splitting\n",
    "df_train, df_test = df_reg.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c70d6",
   "metadata": {},
   "source": [
    "### Build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f843c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "r_lr = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ea783834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Random Forest Regressor\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='label')\n",
    "r_rf = rf.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9de843e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Gradient Boosted Tree Regressor\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol='label', maxIter=10)\n",
    "r_gbt = gbt.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae15fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol='label')\n",
    "r_dt = dt.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f6c98e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/Users/Ghaliah_Maher/spark-3.3.1-bin-hadoop3/jars/spark-core_2.12-3.3.1.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "# Lets make the predictions on the testing set\n",
    "pred_dt = r_dt.transform(df_test)\n",
    "pred_rf = r_rf.transform(df_test)\n",
    "pred_lr = r_lr.transform(df_test)\n",
    "pred_gbt = r_gbt.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed1722",
   "metadata": {},
   "source": [
    "### Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2058158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43d5fdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#list our regrassion models\n",
    "models = [pred_rf, pred_gbt, pred_dt, pred_lr]\n",
    "\n",
    "evaluator_R = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='r2')\n",
    "\n",
    "evaluator_RMSE = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='rmse')\n",
    "\n",
    "evaluator_MAE = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='mae')\n",
    "\n",
    "# Empty lists that will store the scores for each metric for each model.\n",
    "R2 = []\n",
    "RMSE = []\n",
    "MAE = []\n",
    "\n",
    "# loop to populate the empty lists with scores of models for each metric.\n",
    "for model in models:\n",
    "    R2.append(evaluator_R.evaluate(model))\n",
    "    RMSE.append(evaluator_RMSE.evaluate(model))\n",
    "    MAE.append(evaluator_MAE.evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1c382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will convert all lists created above into a dataframe for easy viewing.\n",
    "df_ev_reg = pd.DataFrame(list(zip(R2, RMSE, MAE)), \n",
    "                     columns = ['R-squared', 'Root Mean Squared Error', 'Mean Absolute Error'],\n",
    "                     index = ['Random Forest Regressor', 'Gradient Boosted Trees Regressor', 'Decision Tree Regressor', 'Linear Regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "708fe8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Regressor</th>\n",
       "      <td>0.728885</td>\n",
       "      <td>5662.905996</td>\n",
       "      <td>2180.794710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosted Trees Regressor</th>\n",
       "      <td>0.786523</td>\n",
       "      <td>5025.027490</td>\n",
       "      <td>1083.505837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <td>0.780244</td>\n",
       "      <td>5098.392648</td>\n",
       "      <td>1379.815423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396031</td>\n",
       "      <td>0.242107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  R-squared  Root Mean Squared Error  \\\n",
       "Random Forest Regressor            0.728885              5662.905996   \n",
       "Gradient Boosted Trees Regressor   0.786523              5025.027490   \n",
       "Decision Tree Regressor            0.780244              5098.392648   \n",
       "Linear Regression                  1.000000                 0.396031   \n",
       "\n",
       "                                  Mean Absolute Error  \n",
       "Random Forest Regressor                   2180.794710  \n",
       "Gradient Boosted Trees Regressor          1083.505837  \n",
       "Decision Tree Regressor                   1379.815423  \n",
       "Linear Regression                            0.242107  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ev_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db41bb4",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning - Best Two Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fdd937",
   "metadata": {},
   "source": [
    "Choosing Decision Tree and Gradient Boosted Trees instead of Linear Regression because of the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4214a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0b386e",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "edc12fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize our grid \n",
    "grid2 = ParamGridBuilder().addGrid(dt.maxDepth, [5, 10, 15, 20 , 25]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bbe5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CrossValidator\n",
    "cv_reg2 = CrossValidator(estimator=dt, estimatorParamMaps=grid2, evaluator=evaluator_R, parallelism=2, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16b4c68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:54:52 WARN DAGScheduler: Broadcasting large task binary with size 1475.9 KiB\n",
      "22/12/26 14:54:53 WARN DAGScheduler: Broadcasting large task binary with size 1475.9 KiB\n",
      "22/12/26 14:54:53 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:54:53 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:54:54 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "22/12/26 14:54:55 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:54:55 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "22/12/26 14:54:55 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:54:56 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:54:57 WARN DAGScheduler: Broadcasting large task binary with size 1300.1 KiB\n",
      "22/12/26 14:54:58 WARN DAGScheduler: Broadcasting large task binary with size 11.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8779:>                                                     (0 + 10) / 10]\r",
      "\r",
      "[Stage 8779:>             (0 + 10) / 10][Stage 8781:>              (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:54:59 WARN DAGScheduler: Broadcasting large task binary with size 1657.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8780:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:01 WARN DAGScheduler: Broadcasting large task binary with size 15.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:02 WARN DAGScheduler: Broadcasting large task binary with size 2000.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:04 WARN DAGScheduler: Broadcasting large task binary with size 1475.9 KiB\n",
      "22/12/26 14:55:04 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:55:05 WARN DAGScheduler: Broadcasting large task binary with size 12.1 MiB\n",
      "22/12/26 14:55:06 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8801:>                                                     (0 + 10) / 10]\r",
      "\r",
      "[Stage 8800:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:06 WARN DAGScheduler: Broadcasting large task binary with size 12.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8800:============================>                           (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:07 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "22/12/26 14:55:09 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8805:>                                                     (0 + 10) / 10]\r",
      "\r",
      "[Stage 8805:============================================>          (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:09 WARN DAGScheduler: Broadcasting large task binary with size 1300.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:10 WARN DAGScheduler: Broadcasting large task binary with size 11.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8807:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1657.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8808:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:13 WARN DAGScheduler: Broadcasting large task binary with size 15.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8809:===========================>                           (5 + 5) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:14 WARN DAGScheduler: Broadcasting large task binary with size 2000.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8810:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:16 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8811:======================================>                (7 + 3) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:17 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:19 WARN DAGScheduler: Broadcasting large task binary with size 26.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8813:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:21 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8815:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:23 WARN DAGScheduler: Broadcasting large task binary with size 32.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8815:=================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:26 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8817:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:28 WARN DAGScheduler: Broadcasting large task binary with size 38.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8817:============================================>          (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:30 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8819:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:33 WARN DAGScheduler: Broadcasting large task binary with size 44.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8819:============================================>          (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:36 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:38 WARN DAGScheduler: Broadcasting large task binary with size 29.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8821:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:40 WARN DAGScheduler: Broadcasting large task binary with size 29.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8823:>               (0 + 1) / 1][Stage 8824:>               (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:55:47 WARN BlockManager: Block rdd_20384_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:10 WARN DAGScheduler: Broadcasting large task binary with size 1026.8 KiB\n",
      "22/12/26 14:56:11 WARN DAGScheduler: Broadcasting large task binary with size 1026.8 KiB\n",
      "22/12/26 14:56:11 WARN DAGScheduler: Broadcasting large task binary with size 1540.5 KiB\n",
      "22/12/26 14:56:11 WARN DAGScheduler: Broadcasting large task binary with size 1540.5 KiB\n",
      "22/12/26 14:56:11 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:56:12 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:56:12 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "22/12/26 14:56:13 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:56:13 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:56:13 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "22/12/26 14:56:15 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n",
      "22/12/26 14:56:15 WARN DAGScheduler: Broadcasting large task binary with size 1272.8 KiB\n",
      "22/12/26 14:56:16 WARN DAGScheduler: Broadcasting large task binary with size 11.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:17 WARN DAGScheduler: Broadcasting large task binary with size 1623.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8966:=================================================>     (9 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:18 WARN DAGScheduler: Broadcasting large task binary with size 1026.8 KiB\n",
      "22/12/26 14:56:18 WARN DAGScheduler: Broadcasting large task binary with size 1540.5 KiB\n",
      "22/12/26 14:56:19 WARN DAGScheduler: Broadcasting large task binary with size 15.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:20 WARN DAGScheduler: Broadcasting large task binary with size 1963.0 KiB\n",
      "22/12/26 14:56:20 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:56:21 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8979:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:22 WARN DAGScheduler: Broadcasting large task binary with size 12.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:22 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "22/12/26 14:56:23 WARN DAGScheduler: Broadcasting large task binary with size 12.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:24 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8985:======================================>                (7 + 3) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:24 WARN DAGScheduler: Broadcasting large task binary with size 1272.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:25 WARN DAGScheduler: Broadcasting large task binary with size 11.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8987:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:26 WARN DAGScheduler: Broadcasting large task binary with size 1623.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:28 WARN DAGScheduler: Broadcasting large task binary with size 15.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8989:======================>                                (4 + 6) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:29 WARN DAGScheduler: Broadcasting large task binary with size 1963.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:30 WARN DAGScheduler: Broadcasting large task binary with size 20.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8991:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:31 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:33 WARN DAGScheduler: Broadcasting large task binary with size 26.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8993:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:35 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8994:===========>                                           (2 + 8) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:37 WARN DAGScheduler: Broadcasting large task binary with size 32.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8995:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:39 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8997:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:41 WARN DAGScheduler: Broadcasting large task binary with size 38.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8997:=================================>                     (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:43 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8999:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:46 WARN DAGScheduler: Broadcasting large task binary with size 44.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8999:===========================>                           (5 + 5) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:49 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:52 WARN DAGScheduler: Broadcasting large task binary with size 29.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9002:>                                                       (0 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:56:54 WARN DAGScheduler: Broadcasting large task binary with size 29.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9003:>               (0 + 1) / 1][Stage 9004:>               (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:01 WARN BlockManager: Block rdd_20769_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:22 WARN DAGScheduler: Broadcasting large task binary with size 1459.5 KiB\n",
      "22/12/26 14:57:22 WARN DAGScheduler: Broadcasting large task binary with size 1459.5 KiB\n",
      "22/12/26 14:57:22 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:57:22 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:57:23 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "22/12/26 14:57:24 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:57:24 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "22/12/26 14:57:24 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:57:25 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:26 WARN DAGScheduler: Broadcasting large task binary with size 1279.9 KiB\n",
      "22/12/26 14:57:27 WARN DAGScheduler: Broadcasting large task binary with size 11.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:28 WARN DAGScheduler: Broadcasting large task binary with size 1637.4 KiB\n",
      "22/12/26 14:57:30 WARN DAGScheduler: Broadcasting large task binary with size 15.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:31 WARN DAGScheduler: Broadcasting large task binary with size 1978.3 KiB\n",
      "22/12/26 14:57:31 WARN DAGScheduler: Broadcasting large task binary with size 1459.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9154:=======>       (5 + 5) / 10][Stage 9155:>              (0 + 5) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:32 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:57:33 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "22/12/26 14:57:34 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "22/12/26 14:57:34 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9162:>             (0 + 10) / 10][Stage 9164:>               (0 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:35 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:36 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9165:>                                                     (0 + 10) / 10]\r",
      "\r",
      "[Stage 9165:=================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:36 WARN DAGScheduler: Broadcasting large task binary with size 1279.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:37 WARN DAGScheduler: Broadcasting large task binary with size 11.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9167:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:38 WARN DAGScheduler: Broadcasting large task binary with size 1637.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:40 WARN DAGScheduler: Broadcasting large task binary with size 15.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9169:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:41 WARN DAGScheduler: Broadcasting large task binary with size 1978.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:42 WARN DAGScheduler: Broadcasting large task binary with size 20.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9171:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:44 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9172:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:46 WARN DAGScheduler: Broadcasting large task binary with size 26.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9173:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:47 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9174:>                                                     (0 + 10) / 10]\r",
      "\r",
      "[Stage 9174:======================================================(10 + 0) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:49 WARN DAGScheduler: Broadcasting large task binary with size 32.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9175:======================================>                (7 + 3) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:51 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9177:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:54 WARN DAGScheduler: Broadcasting large task binary with size 38.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9177:===========================>                           (5 + 5) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:56 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9179:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:57:59 WARN DAGScheduler: Broadcasting large task binary with size 44.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9179:=================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:01 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:04 WARN DAGScheduler: Broadcasting large task binary with size 29.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9182:>                                                       (0 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:06 WARN DAGScheduler: Broadcasting large task binary with size 29.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9183:>               (0 + 1) / 1][Stage 9184:>               (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:13 WARN BlockManager: Block rdd_21154_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:34 WARN DAGScheduler: Broadcasting large task binary with size 1008.0 KiB\n",
      "22/12/26 14:58:34 WARN DAGScheduler: Broadcasting large task binary with size 1008.0 KiB\n",
      "22/12/26 14:58:34 WARN DAGScheduler: Broadcasting large task binary with size 1533.2 KiB\n",
      "22/12/26 14:58:34 WARN DAGScheduler: Broadcasting large task binary with size 1533.2 KiB\n",
      "22/12/26 14:58:35 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:58:35 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:58:36 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "22/12/26 14:58:36 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:58:37 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "22/12/26 14:58:37 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/12/26 14:58:37 WARN DAGScheduler: Broadcasting large task binary with size 1013.2 KiB\n",
      "22/12/26 14:58:38 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9305:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:39 WARN DAGScheduler: Broadcasting large task binary with size 1360.3 KiB\n",
      "22/12/26 14:58:40 WARN DAGScheduler: Broadcasting large task binary with size 11.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:41 WARN DAGScheduler: Broadcasting large task binary with size 1726.8 KiB\n",
      "22/12/26 14:58:42 WARN DAGScheduler: Broadcasting large task binary with size 1008.0 KiB\n",
      "22/12/26 14:58:42 WARN DAGScheduler: Broadcasting large task binary with size 16.2 MiB\n",
      "22/12/26 14:58:42 WARN DAGScheduler: Broadcasting large task binary with size 1533.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9333:==========>    (7 + 3) / 10][Stage 9335:>              (0 + 7) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:44 WARN DAGScheduler: Broadcasting large task binary with size 2041.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:44 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:58:45 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9339:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:46 WARN DAGScheduler: Broadcasting large task binary with size 12.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9340:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:46 WARN DAGScheduler: Broadcasting large task binary with size 12.6 MiB\n",
      "22/12/26 14:58:47 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "22/12/26 14:58:47 WARN DAGScheduler: Broadcasting large task binary with size 1013.2 KiB\n",
      "22/12/26 14:58:48 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9345:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:49 WARN DAGScheduler: Broadcasting large task binary with size 1360.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9346:============================================>          (8 + 2) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:50 WARN DAGScheduler: Broadcasting large task binary with size 11.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9347:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:51 WARN DAGScheduler: Broadcasting large task binary with size 1726.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:52 WARN DAGScheduler: Broadcasting large task binary with size 16.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9349:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:53 WARN DAGScheduler: Broadcasting large task binary with size 2041.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:54 WARN DAGScheduler: Broadcasting large task binary with size 21.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9351:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:56 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9352:=================================================>     (9 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:58 WARN DAGScheduler: Broadcasting large task binary with size 27.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9353:======================================>                (7 + 3) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:58:59 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:02 WARN DAGScheduler: Broadcasting large task binary with size 33.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9355:=====>                                                 (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:04 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9357:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:06 WARN DAGScheduler: Broadcasting large task binary with size 39.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9357:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:08 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9359:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:11 WARN DAGScheduler: Broadcasting large task binary with size 45.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9359:============================================>          (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:14 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9360:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:16 WARN DAGScheduler: Broadcasting large task binary with size 30.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9361:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:18 WARN DAGScheduler: Broadcasting large task binary with size 30.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:51 WARN DAGScheduler: Broadcasting large task binary with size 1007.7 KiB\n",
      "22/12/26 14:59:51 WARN DAGScheduler: Broadcasting large task binary with size 1007.7 KiB\n",
      "22/12/26 14:59:51 WARN DAGScheduler: Broadcasting large task binary with size 1509.9 KiB\n",
      "22/12/26 14:59:51 WARN DAGScheduler: Broadcasting large task binary with size 1509.9 KiB\n",
      "22/12/26 14:59:52 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:59:52 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 14:59:53 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "22/12/26 14:59:54 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/12/26 14:59:54 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "22/12/26 14:59:54 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9477:================>                                      (3 + 7) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:55 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9484:>              (0 + 0) / 10][Stage 9485:>             (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:56 WARN DAGScheduler: Broadcasting large task binary with size 1313.6 KiB\n",
      "22/12/26 14:59:57 WARN DAGScheduler: Broadcasting large task binary with size 11.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:59:58 WARN DAGScheduler: Broadcasting large task binary with size 1664.4 KiB\n",
      "22/12/26 14:59:59 WARN DAGScheduler: Broadcasting large task binary with size 15.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:00 WARN DAGScheduler: Broadcasting large task binary with size 1007.7 KiB\n",
      "22/12/26 15:00:00 WARN DAGScheduler: Broadcasting large task binary with size 2019.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9512:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:01 WARN DAGScheduler: Broadcasting large task binary with size 1509.9 KiB\n",
      "22/12/26 15:00:02 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/12/26 15:00:03 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9519:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:03 WARN DAGScheduler: Broadcasting large task binary with size 12.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:04 WARN DAGScheduler: Broadcasting large task binary with size 12.2 MiB\n",
      "22/12/26 15:00:04 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "22/12/26 15:00:06 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9525:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:06 WARN DAGScheduler: Broadcasting large task binary with size 1313.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9526:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:07 WARN DAGScheduler: Broadcasting large task binary with size 11.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9527:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:08 WARN DAGScheduler: Broadcasting large task binary with size 1664.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9528:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:10 WARN DAGScheduler: Broadcasting large task binary with size 15.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9529:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:11 WARN DAGScheduler: Broadcasting large task binary with size 2019.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9530:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:13 WARN DAGScheduler: Broadcasting large task binary with size 20.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9531:============================================>          (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:15 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:17 WARN DAGScheduler: Broadcasting large task binary with size 26.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9533:>                                                      (0 + 0) / 10]\r",
      "\r",
      "[Stage 9533:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:19 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9535:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:21 WARN DAGScheduler: Broadcasting large task binary with size 32.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9535:=================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:24 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9537:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:27 WARN DAGScheduler: Broadcasting large task binary with size 39.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9537:=================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:29 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9539:>                                                      (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:32 WARN DAGScheduler: Broadcasting large task binary with size 45.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9539:============================================>          (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:34 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9540:>                                                     (0 + 10) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:37 WARN DAGScheduler: Broadcasting large task binary with size 30.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9541:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:00:39 WARN DAGScheduler: Broadcasting large task binary with size 30.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "cv_reg2Model = cv_reg2.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d7d4884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7802437582084216"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_R.evaluate(cv_reg2Model.transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c339aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7720932742789746,\n",
       " 0.757863172093168,\n",
       " 0.6773178566972267,\n",
       " 0.5834472480828815,\n",
       " 0.5484308788230956]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average metrics on 4 different models \n",
    "cv_reg2Model.avgMetrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0e2fc",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f104417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize our grid \n",
    "grid = ParamGridBuilder().addGrid(gbt.maxIter, [40, 30, 15, 20 , 25]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e30b8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CrossValidator\n",
    "cv_reg = CrossValidator(estimator=gbt, estimatorParamMaps=grid, evaluator=evaluator_R, parallelism=2, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "710f7871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "cv_regModel = cv_reg.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c145a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7869387457164968"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_R.evaluate(cv_regModel.transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1ba3a356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7704864171768898,\n",
       " 0.770883392964161,\n",
       " 0.7707110220329045,\n",
       " 0.7708912026089141,\n",
       " 0.7708921394838875]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average metrics on 4 different models \n",
    "cv_regModel.avgMetrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eda49b",
   "metadata": {},
   "source": [
    "### Pipeline - Best Two Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "36a24979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10fd8c",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b1dfe183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline containing PCA and Decision Tree\n",
    "pca = PCA(k=5, inputCol='features', outputCol='pcaFeature')\n",
    "dt_1 = DecisionTreeRegressor(maxDepth=10)\n",
    "pipeline = Pipeline (stages=[pca, dt_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a46d265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "pipeline_model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3d8aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7674569146092332"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_R.evaluate(pipeline_model.transform(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31419c74",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3b977f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline containing PCA and Gradient Boosted Trees \n",
    "pca1 = PCA(k=5, inputCol='features', outputCol='pcaFeature')\n",
    "GBTR_1 = GBTRegressor(maxIter = 20)\n",
    "pipeline2 = Pipeline (stages=[pca1, GBTR_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "69eeb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "pipeline_model2 = pipeline2.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3bb5da61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7868486082923655"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "evaluator_R.evaluate(pipeline_model2.transform(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1535a62",
   "metadata": {},
   "source": [
    "# THANK YOU :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
